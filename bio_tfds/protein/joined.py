"""Protein datasets that come from joining other datasets here."""
import collections

import tensorflow as tf
import tensorflow_datasets.public_api as tfds

from bio_tfds.constants import DEFAULT_TFDS_DATA_DIR
from bio_tfds.protein import pfam
from bio_tfds.protein import uniref


class UniRef50WithPfamRegions(tfds.core.GeneratorBasedBuilder):
    """UniRef50 sequences with Pfam regions annotated.

    You must have the UniRef50 and Pfam downloaded and prepared before
    building this dataset.
    """

    VERSION = tfds.core.Version("1.0.0")

    UNSTABLE = "The current_release is updated every 8 weeks."

    def _info(self):
        return tfds.core.DatasetInfo(
            builder=self,
            description="The uniref.UniRef50 dataset with regions from pfam.PfamARegionsUniprot attached.",
            features=tfds.features.FeaturesDict(
                {
                    # The primary accession number of the UniRef cluster.
                    # The UniRef50 identifier is generated by placing
                    # "UniRef50_" prefix before the UniProtKB accession number
                    # or UniParc identifier of the representative UniProtKB or UniParc entry.
                    "unique_identifier": tfds.features.Text(),
                    # The name of the UniRef cluster.
                    "cluster_name": tfds.features.Text(),
                    # The number of UniRef cluster members.
                    "num_members": tf.int32,
                    # The scientific name of the lowest common taxon shared by all
                    # UniRef cluster members.
                    "tax_name": tfds.features.Text(),
                    # Thee id of the lowest common taxon shared by all
                    # UniRef cluster members.
                    "tax_id": tfds.features.Text(),
                    # The entry name of the representative member of the
                    # UniRef cluster.
                    "representative_member": tfds.features.Text(),
                    # The uppercase AA sequence of the protein.
                    "aa_sequence": tfds.features.Text(),
                    # The information from Pfam. A list of all features present on
                    # the representative member.
                    "pfam_regions": tfds.features.Sequence(
                        {
                            # The accession number of the PfamA entry.
                            "pfam_acc": tfds.features.Text(),
                            # The 0-BASED, INCLUSIVE start index of the region in the
                            # protein's AA sequence. Note that this is different than
                            # in the raw data, which is 1-based and inclusive.
                            "start": tf.int32,
                            # The 0-BASED, EXCLUSIVE end index of the region in the
                            # protein's AA sequence. The raw data is 1-based and
                            # inclusive, which works out to be the same.
                            "end": tf.int32,
                        }
                    ),
                }
            ),
            homepage="",
            citation=f"{pfam._CITATION}\n{uniref._CITATION}",
        )

    def _split_generators(self, dl_manager):
        return [
            tfds.core.SplitGenerator(
                name=tfds.Split.TRAIN,
                gen_kwargs={"split": "train"},
            ),
        ]

    def _get_uniref50_acc_set(self, split):
        ds = uniref.UniRef50().as_dataset(split=split)
        ds = ds.map(
            lambda x: x["unique_identifier"],
            num_parallel_calls=tf.data.experimental.AUTOTUNE,
        )
        ds = ds.prefetch(tf.data.experimental.AUTOTUNE)
        return set(
            uniref.UniRef50.extract_uniprot_acc(s) for s in ds.as_numpy_iterator()
        )

    def _get_acc_to_regions(self, split, uniref50_acc_set):
        ds = pfam.PfamARegionsUniprot().as_dataset(split=split)
        ds = ds.prefetch(tf.data.experimental.AUTOTUNE)

        default_value = lambda: {"pfam_acc": [], "start": [], "end": []}

        acc_to_regions = collections.defaultdict(default_value)
        for x in ds.as_numpy_iterator():
            acc = x["uniprot_acc"]
            if acc not in uniref50_acc_set:
                continue
            regions = acc_to_regions[acc]
            regions["pfam_acc"].append(x["pfam_acc"])
            regions["start"].append(x["start"])
            regions["end"].append(x["end"])
        return acc_to_regions

    def _generate_examples(self, split):
        print("Starting to generate examples.")

        uniref50_acc_set = self._get_uniref50_acc_set(split)
        print("Created a set of UniRef50 accessions.")

        # Get the regions for only the reference sequences in UniRef50. This
        # is to save memory.
        acc_to_regions = self._get_acc_to_regions(split, uniref50_acc_set)
        print("Created a map from UniRef50 accessions to Pfam regions.")

        ds = uniref.UniRef50().as_dataset(split=split)
        ds = ds.prefetch(tf.data.experimental.AUTOTUNE)
        for x in ds.as_numpy_iterator():
            acc = x["unique_identifier"]
            x["pfam_regions"] = acc_to_regions[acc]
            yield acc, x
